{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Autoencoders on fMRI Images for Automatic Data Generation\n",
    "In this notebook and the corresponding repository, we will focus on the use of adversarial autoencoders to attack problems relating to generating a usable embedding for the space of sMRI images for the purpose of understanding psychiatric diseases.\n",
    "\n",
    "This notebook written for and executed with Python 3.5, Keras 2.1.2 and Tensorflow r1.4.\n",
    "### Data Setup\n",
    "We will be using specifically preprocessed data for the project from ABIDE 1&2. Assuming that the instructions have been followed, we continue by selecting the 2mm dataset and ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import gzip\n",
    "nii_files = []\n",
    "for dirpath, sf, files in os.walk('depi-dataset_01'):\n",
    "    if 'anat_mni_2mm.nii.gz' in files:\n",
    "        nii_files.append(os.path.join(dirpath, 'anat_mni_2mm.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in nii_files:\n",
    "    decompressed_file = gzip.open(i)\n",
    "    out_path = i.replace('/','_')[:-3]\n",
    "    with open('depi_nii/' + out_path, 'wb') as outfile:\n",
    "        outfile.write(decompressed_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "Data processing for this dataset is relatively straightforward; we delete the final voxel (which is always 0) so that the dimensionality of the spatial tensor has a high GCD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import copy\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "def save_large_dataset(file_name, variable):\n",
    "    h5f = h5py.File(file_name + '.h5', 'w')\n",
    "    h5f.create_dataset('variable', data=variable)\n",
    "    h5f.close()\n",
    "\n",
    "indir = 'depi_nii/'\n",
    "Xs = []\n",
    "for root, dirs, filenames in os.walk(indir):\n",
    "    for f in filenames:\n",
    "        if '.nii' == f[-4:]:\n",
    "            img = nib.load(indir + f)\n",
    "            data = img.dataobj # Get the data object\n",
    "            data = data[:-1,:-1,:-1] # Clean the last dimension for a high GCD (all values are 0)\n",
    "            X = np.expand_dims(data, -1)\n",
    "            X = X / np.max(X)\n",
    "            X = X.astype('float32')\n",
    "            X = np.expand_dims(X, 0)\n",
    "            print('Shape: ', X.shape)\n",
    "            Xs.append(X)\n",
    "            \n",
    "Xa = np.vstack(Xs)\n",
    "save_large_dataset('Xa', Xa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "We will use the [keras-adversarial library](https://github.com/bstriner/keras-adversarial) to help us with our training. We use [this example](https://github.com/bstriner/keras-adversarial/blob/master/examples/example_aae_cifar10.py) as a basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:58: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:63: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:64: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:69: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(1, (3, 3, 3), padding=\"same\", activation=\"linear\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:78: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:82: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:83: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), padding=\"same\", activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               450       \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 5, 6, 5, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 5, 6, 5, 64)       1792      \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 5, 6, 5, 64)       110656    \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 5, 6, 5, 64)       110656    \n",
      "_________________________________________________________________\n",
      "up_sampling3d_3 (UpSampling3 (None, 15, 18, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 15, 18, 15, 32)    55328     \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 15, 18, 15, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 15, 18, 15, 32)    27680     \n",
      "_________________________________________________________________\n",
      "up_sampling3d_4 (UpSampling3 (None, 45, 54, 45, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 45, 54, 45, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 45, 54, 45, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 45, 54, 45, 32)    27680     \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 45, 54, 45, 1)     865       \n",
      "=================================================================\n",
      "Total params: 418,147\n",
      "Trainable params: 418,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 45, 54, 45, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 45, 54, 45, 64)    1792      \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 45, 54, 45, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 45, 54, 45, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 15, 18, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 15, 18, 15, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 15, 18, 15, 64)    110656    \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 15, 18, 15, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 5, 6, 5, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 19202     \n",
      "=================================================================\n",
      "Total params: 574,274\n",
      "Trainable params: 574,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 264,705\n",
      "Trainable params: 264,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 45, 54, 45, 1)     0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 574274    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 45, 54, 45, 1)     418147    \n",
      "=================================================================\n",
      "Total params: 992,421\n",
      "Trainable params: 992,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2000 samples, validate on 200 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[50,45,54,45,64]\n\t [[Node: encoder_2/conv3d_27/convolution = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_5_0_0/_729, conv3d_27/kernel/read)]]\n\t [[Node: loss_2/xpred_loss/Mean_3/_879 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4366_loss_2/xpred_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'encoder_2/conv3d_27/convolution', defined at:\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-006e0796b59f>\", line 164, in <module>\n    example_aae(\"aae-smri-6\", AdversarialOptimizerSimultaneous(), latent_dim=2)\n  File \"<ipython-input-2-006e0796b59f>\", line 110, in example_aae\n    autoencoder = Model(encoder.inputs, generator(encoder(encoder.inputs)))\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 172, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3370, in conv3d\n    data_format=tf_data_format)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 847, in conv3d\n    padding=padding, data_format=data_format, name=name)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,45,54,45,64]\n\t [[Node: encoder_2/conv3d_27/convolution = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_5_0_0/_729, conv3d_27/kernel/read)]]\n\t [[Node: loss_2/xpred_loss/Mean_3/_879 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4366_loss_2/xpred_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,45,54,45,64]\n\t [[Node: encoder_2/conv3d_27/convolution = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_5_0_0/_729, conv3d_27/kernel/read)]]\n\t [[Node: loss_2/xpred_loss/Mean_3/_879 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4366_loss_2/xpred_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-006e0796b59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"discriminator.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mexample_aae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"aae-smri-6\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdversarialOptimizerSimultaneous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-006e0796b59f>\u001b[0m in \u001b[0;36mexample_aae\u001b[0;34m(path, adversarial_optimizer, latent_dim)\u001b[0m\n\u001b[1;32m    151\u001b[0m     history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest),\n\u001b[1;32m    152\u001b[0m                   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                   nb_epoch=300, batch_size=50)\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# save history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras_adversarial-0.0.3-py3.5.egg/keras_adversarial/legacy.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, x, y, nb_epoch, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,45,54,45,64]\n\t [[Node: encoder_2/conv3d_27/convolution = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_5_0_0/_729, conv3d_27/kernel/read)]]\n\t [[Node: loss_2/xpred_loss/Mean_3/_879 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4366_loss_2/xpred_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'encoder_2/conv3d_27/convolution', defined at:\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-006e0796b59f>\", line 164, in <module>\n    example_aae(\"aae-smri-6\", AdversarialOptimizerSimultaneous(), latent_dim=2)\n  File \"<ipython-input-2-006e0796b59f>\", line 110, in example_aae\n    autoencoder = Model(encoder.inputs, generator(encoder(encoder.inputs)))\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 2061, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\", line 2212, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/layers/convolutional.py\", line 172, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 3370, in conv3d\n    data_format=tf_data_format)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 847, in conv3d\n    padding=padding, data_format=data_format, name=name)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,45,54,45,64]\n\t [[Node: encoder_2/conv3d_27/convolution = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", padding=\"SAME\", strides=[1, 1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](_arg_input_5_0_0/_729, conv3d_27/kernel/read)]]\n\t [[Node: loss_2/xpred_loss/Mean_3/_879 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4366_loss_2/xpred_loss/Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "\n",
    "from keras.layers import Input, Reshape, Flatten, Lambda, Dense, Conv3D, MaxPooling3D, UpSampling3D, TimeDistributed\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras_adversarial.legacy import l1l2, Dense, fit, Convolution2D\n",
    "from keras_adversarial import AdversarialModel, fix_names, n_choice\n",
    "from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling\n",
    "from keras.layers import LeakyReLU, Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class SamplingLayer2D(Layer):\n",
    "    def __init__(self, batch_size, n = 10, std = 1.0, **kwargs):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.std = std\n",
    "        super(SamplingLayer2D, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.in_shape = input_shape\n",
    "        choices = list(np.arange(self.n))\n",
    "        choice_weights = np.arange(self.n) * (2 * np.pi) / (self.n) \n",
    "        W = np.vstack((np.cos(choice_weights), np.sin(choice_weights))).T\n",
    "        self.W = K.variable(value=W)\n",
    "        super(SamplingLayer2D, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        x = tf.tile(self.W, tf.constant([self.batch_size, 1]))\n",
    "        y = x + K.random_normal(shape=K.shape(x), mean = 0.0, stddev=self.std)\n",
    "        y = K.reshape(y, tf.stack((-1, 2)))\n",
    "        y = tf.random_shuffle(y)\n",
    "        y = y[:self.batch_size, :]\n",
    "        y = K.reshape(y, tf.stack((-1, 2)))\n",
    "        return y\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (self.batch_size, 2)\n",
    "\n",
    "def load_large_dataset(file_name):\n",
    "    h5f = h5py.File(file_name + '.h5','r')\n",
    "    variable = h5f['variable'][:]\n",
    "    h5f.close()\n",
    "    return variable\n",
    "\n",
    "X = load_large_dataset('Xa')\n",
    "X = X[:,::2,::2,::2,:]\n",
    "def model_generator(latent_dim):\n",
    "    latent_dim_2 = 3\n",
    "    input_layer = Input((latent_dim,))\n",
    "    x = Dense(5*6*5)(input_layer)\n",
    "    x = Reshape((5, 6, 5, 1))(x)\n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = UpSampling3D((3, 3, 3))(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = UpSampling3D((3, 3, 3))(x)\n",
    "    #x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    #x = UpSampling3D((2, 2, 2))(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    x = Conv3D(32, 3, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    generated = Conv3D(1, 3, 3, 3, activation='linear', border_mode='same')(x)\n",
    "    return Model(input_layer, generated, name='decoder')\n",
    "\n",
    "\n",
    "def model_encoder(latent_dim, input_shape, reg=lambda: l1l2(1e-7, 0)):\n",
    "    input_layer = Input(shape=X.shape[1:]) # Create the Input Layer\n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(input_layer) \n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x) \n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x) \n",
    "    x = MaxPooling3D((3, 3, 3), padding='same')(x)\n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x) \n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x) \n",
    "    x = Conv3D(64, 3, 3, 3, activation='relu', border_mode='same')(x) \n",
    "    x = MaxPooling3D((3, 3, 3), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(latent_dim)(x)\n",
    "    #mu = Dense(latent_dim, name=\"encoder_mu\", W_regularizer=reg())(x)\n",
    "    #log_sigma_sq = Dense(latent_dim, name=\"encoder_log_sigma_sq\", W_regularizer=reg())(x)\n",
    "    #encoded = Lambda(lambda mulss : mulss[0] + K.random_normal(K.shape(mulss[0])) * K.exp(mulss[1] / 2),\n",
    "    #           output_shape= (latent_dim,))([mu, log_sigma_sq])\n",
    "    return Model(input_layer, encoded, name=\"encoder\")\n",
    "\n",
    "\n",
    "def model_discriminator(latent_dim, output_dim=1, units=256, reg=lambda: l1l2(1e-7, 1e-7)):\n",
    "    input_layer = Input((latent_dim,))\n",
    "    x = Dense(512, activation = 'relu')(input_layer)\n",
    "    x = Dense(512, activation = 'relu')(x)\n",
    "    y = Dense(1, activation = 'sigmoid')(x)\n",
    "    return Model(input_layer, y)\n",
    "\n",
    "\n",
    "def example_aae(path, adversarial_optimizer, latent_dim = 32):\n",
    "    input_shape = X.shape[1:]\n",
    "\n",
    "    # Specify the generator (z -> x)\n",
    "    generator = model_generator(latent_dim)\n",
    "    # Specify the encoder (x -> z)\n",
    "    encoder = model_encoder(latent_dim, input_shape)\n",
    "    # Combining the encoder and the generator, specify the autoencoder (x -> x')\n",
    "    autoencoder = Model(encoder.inputs, generator(encoder(encoder.inputs)))\n",
    "    # Specify the discriminator (z -> y)\n",
    "    discriminator = model_discriminator(latent_dim)\n",
    "\n",
    "    # build the AAE\n",
    "    x = encoder.inputs[0]\n",
    "    z = encoder(x)\n",
    "    xpred = generator(z)\n",
    "    zreal = SamplingLayer2D(50)(x)\n",
    "    yreal = discriminator(zreal)\n",
    "    yfake = discriminator(z)\n",
    "    aae = Model(x, fix_names([xpred, yfake, yreal], [\"xpred\", \"yfake\", \"yreal\"]))\n",
    "\n",
    "    # Generate summaries for the models\n",
    "    generator.summary()\n",
    "    encoder.summary()\n",
    "    discriminator.summary()\n",
    "    autoencoder.summary()\n",
    "\n",
    "    # Build the adversarial model\n",
    "    generative_params = generator.trainable_weights + encoder.trainable_weights\n",
    "    model = AdversarialModel(base_model=aae,\n",
    "                             player_params=[generative_params, discriminator.trainable_weights],\n",
    "                             player_names=[\"generator\", \"discriminator\"])\n",
    "    model.adversarial_compile(adversarial_optimizer=adversarial_optimizer,\n",
    "                              player_optimizers = [Adam(3e-4, decay=1e-4), Adam(1e-3, decay=1e-4)],\n",
    "                              loss={\"yfake\": \"binary_crossentropy\", \"yreal\": \"binary_crossentropy\",\n",
    "                                    \"xpred\": \"mae\"},\n",
    "                              player_compile_kwargs=[{\"loss_weights\": {\"yfake\": 1e-1, \"yreal\": 1e-1,\n",
    "                                                                       \"xpred\": 1e1}}] * 2)\n",
    "\n",
    "    # Split our data into training and testing\n",
    "    xtrain = X[:2000]\n",
    "    xtest = X[2000:2200]\n",
    "    \n",
    "    # train network\n",
    "    # generator, discriminator; pred, yfake, yreal\n",
    "    n = xtrain.shape[0]\n",
    "    y = [xtrain, np.ones((n,)), np.zeros((n,)), xtrain, np.zeros((n,)), np.ones((n,))]\n",
    "    ntest = xtest.shape[0]\n",
    "    ytest = [xtest, np.ones((ntest,)), np.zeros((ntest,)), xtest, np.zeros((ntest,)), np.ones((ntest,))]\n",
    "    history = fit(model, x=xtrain, y=y, validation_data=(xtest, ytest),\n",
    "                  callbacks=[],\n",
    "                  nb_epoch=300, batch_size=50)\n",
    "\n",
    "    # save history\n",
    "    df = pd.DataFrame(history.history)\n",
    "    df.to_csv(os.path.join(path, \"history.csv\"))\n",
    "\n",
    "    # save model\n",
    "    encoder.save(os.path.join(path, \"encoder.h5\"))\n",
    "    generator.save(os.path.join(path, \"generator.h5\"))\n",
    "    discriminator.save(os.path.join(path, \"discriminator.h5\"))\n",
    "\n",
    "example_aae(\"aae-smri-6\", AdversarialOptimizerSimultaneous(), latent_dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Here, we load up the saved models to test whether our models can produce anything visually impressive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/mehmet/miniconda2/envs/tensorflow/lib/python3.5/site-packages/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.layers import Input, Dense, Conv3D, MaxPooling3D, UpSampling3D, Flatten, TimeDistributed, Reshape\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Permute, TimeDistributed, Activation, Lambda, multiply, subtract, concatenate\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Conv2D, MaxPooling2D\n",
    "from keras.losses import kullback_leibler_divergence\n",
    "from keras.regularizers import L1L2, Regularizer\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "def load_large_dataset(file_name):\n",
    "    h5f = h5py.File(file_name + '.h5','r')\n",
    "    variable = h5f['variable'][:]\n",
    "    h5f.close()\n",
    "    return variable\n",
    "\n",
    "X = load_large_dataset('Xa')\n",
    "X = X[:,::2,::2,::2,:]\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "class SamplingLayer2D(Layer):\n",
    "    def __init__(self, batch_size, n = 10, std = 1.0, **kwargs):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.std = std\n",
    "        super(SamplingLayer2D, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.in_shape = input_shape\n",
    "        choices = list(np.arange(self.n))\n",
    "        choice_weights = np.arange(self.n) * (2 * np.pi) / (self.n) \n",
    "        W = np.vstack((np.cos(choice_weights), np.sin(choice_weights))).T\n",
    "        self.W = K.variable(value=W)\n",
    "        super(SamplingLayer2D, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        #x = tf.einsum('ai,jk->ajk', x, self.W)\n",
    "        x = tf.tile(self.W, tf.constant([self.batch_size, 1]))\n",
    "        #element_choices = tf.convert_to_tensor(self.choices)\n",
    "        #indices = tf.multinomial(tf.log([self.weights]), self.batch_size)\n",
    "        #y = self.W + K.random_normal(shape=K.shape(self.W), mean = 0.0, stddev=self.std)\n",
    "        y = x + K.random_normal(shape=K.shape(x), mean = 0.0, stddev=self.std)\n",
    "        y = K.reshape(y, tf.stack((-1, 2)))\n",
    "        y = tf.random_shuffle(y)\n",
    "        y = y[:self.batch_size, :]\n",
    "        y = K.reshape(y, tf.stack((-1, 2)))\n",
    "        return y\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (self.batch_size, 2)\n",
    "    \n",
    "data = np.zeros((96, 1))\n",
    "\n",
    "i = Input(shape=data.shape[1:])\n",
    "x = SamplingLayer2D(32, std=0.3)(i)\n",
    "\n",
    "sampler = Model(inputs=i, outputs=[x])\n",
    "sampler.compile(optimizer='sgd', loss='mse')\n",
    "\n",
    "zsamples = sampler.predict(data, batch_size = 32)\n",
    "\n",
    "encoder = load_model('aae-smri-6/encoder.h5')\n",
    "generator = load_model('aae-smri-6/generator.h5')\n",
    "#discriminator = load_model('aae-fmri/discriminator.h5')\n",
    "#zsamples = np.random.normal(size=(100, latent_dim))\n",
    "outs = generator.predict(zsamples, batch_size = 2)\n",
    "# random_generator = generator(normal_latent_sampling((X.shape[1], latent_dim,)))(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first show a 2D slice from the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD8CAYAAADAKumpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSOQpUYlI5P1/4WE+VZj2GHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6be014aa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "my_slice = X[0,:,:,30,0]\n",
    "%matplotlib inline\n",
    "plt.imshow(my_slice, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now show an output from the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAD8CAYAAADAKumpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQiJPQxUhJDY8/8BBNBwUSGARM0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6be014a828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "my_slice = outs[45,:,:,30,0]\n",
    "%matplotlib inline\n",
    "plt.imshow(my_slice / np.max(my_slice), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is alive!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
